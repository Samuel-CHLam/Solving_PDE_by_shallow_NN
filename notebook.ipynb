{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONIX+f2Vz2GQPwYIU8G4w2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samuel-CHLam/Solving_PDE_by_shallow_NN/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LSEYw0NA_te",
        "outputId": "d277f556-bd3b-4c0c-95c7-18459c018e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd ./drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./kolmogorov-master-v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IiY18AHCVsS",
        "outputId": "07d55844-4fa5-4c80-cae6-36f798995df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/kolmogorov-master-v2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from tensorflow.python.ops import init_ops\n",
        "from tensorflow.compat.v1.keras import initializers\n",
        "from tensorflow.python.training.moving_averages import assign_moving_average\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "metadata": {
        "id": "PtzDHFEPl_TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neural_net(x, neurons, is_training, name,\n",
        "               mv_decay=0.9, dtype=tf.float32):\n",
        "\n",
        "    def _batch_normyalization(_x):\n",
        "        beta = tf.compat.v1.get_variable('beta', [_x.get_shape()[-1]],\n",
        "                               dtype, init_ops.zeros_initializer())\n",
        "        gamma = tf.compat.v1.get_variable('gamma', [_x.get_shape()[-1]],\n",
        "                                dtype, init_ops.ones_initializer())\n",
        "        mv_mean = tf.compat.v1.get_variable('mv_mean', [_x.get_shape()[-1]],\n",
        "                                  dtype, init_ops.zeros_initializer(),\n",
        "                                  trainable=False)\n",
        "        mv_variance = tf.compat.v1.get_variable('mv_variance', [_x.get_shape()[-1]],\n",
        "                                      dtype, init_ops.ones_initializer(),\n",
        "                                      trainable=False)\n",
        "        mean, variance = tf.nn.moments(x=_x, axes=[0], name='moments')\n",
        "        tf.compat.v1.add_to_collection(tf.compat.v1.GraphKeys.UPDATE_OPS,\n",
        "                             assign_moving_average(mv_mean, mean,\n",
        "                                                   mv_decay, True))\n",
        "        tf.compat.v1.add_to_collection(tf.compat.v1.GraphKeys.UPDATE_OPS,\n",
        "                             assign_moving_average(mv_variance, variance,\n",
        "                                                   mv_decay, False))\n",
        "        mean, variance = tf.cond(pred=is_training,\n",
        "                                 true_fn=lambda: (mean, variance),\n",
        "                                 false_fn=lambda: (mv_mean, mv_variance))\n",
        "        return tf.nn.batch_normalization(_x, mean, variance,\n",
        "                                         beta, gamma, 1e-6)\n",
        "\n",
        "    def _layer(_x, out_size, activation_fn):\n",
        "        w = tf.compat.v1.get_variable('weights',\n",
        "                            [_x.get_shape().as_list()[-1], out_size],\n",
        "                            dtype, initializers.glorot_normal())\n",
        "        return activation_fn(_batch_normalization(tf.matmul(_x, w)))\n",
        "\n",
        "    with tf.compat.v1.variable_scope(name):\n",
        "        x = _batch_normalization(x)\n",
        "        for i in range(len(neurons)):\n",
        "            with tf.compat.v1.variable_scope(f'layer_{i + 1}_'):\n",
        "                x = _layer(x, neurons[i],\n",
        "                           tf.nn.tanh if i < len(neurons)-1 else tf.identity)\n",
        "    return x"
      ],
      "metadata": {
        "id": "hqKQHFdFCsrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kolmogorov_train_and_test(xi, x_sde, phi, u_reference, neurons,\n",
        "                              lr_boundaries, lr_values, train_steps,\n",
        "                              mc_rounds, mc_freq, file_name,\n",
        "                              dtype=tf.float32):\n",
        "\n",
        "    def _approximate_errors():\n",
        "        lr, gs = sess.run([learning_rate, global_step])\n",
        "        l1_err, l2_err, li_err = 0., 0., 0.\n",
        "        rel_l1_err, rel_l2_err, rel_li_err = 0., 0., 0.\n",
        "        for _ in range(mc_rounds):\n",
        "            l1, l2, li, rl1, rl2, rli \\\n",
        "                = sess.run([err_l_1, err_l_2, err_l_inf,\n",
        "                            rel_err_l_1, rel_err_l_2, rel_err_l_inf],\n",
        "                           feed_dict={is_training: False})\n",
        "            l1_err, l2_err, li_err = (l1_err + l1, l2_err + l2,\n",
        "                                      np.maximum(li_err, li))\n",
        "            rel_l1_err, rel_l2_err, rel_li_err \\\n",
        "                = (rel_l1_err + rl1, rel_l2_err + rl2,\n",
        "                   np.maximum(rel_li_err, rli))\n",
        "        l1_err, l2_err = l1_err / mc_rounds, np.sqrt(l2_err / mc_rounds)\n",
        "        rel_l1_err, rel_l2_err \\\n",
        "            = rel_l1_err / mc_rounds, np.sqrt(rel_l2_err / mc_rounds)\n",
        "        t_mc = time.time()\n",
        "        file_out.write('%i, %f, %f, %f, %f, %f, %f, %f, '\n",
        "                       '%f, %f\\n' % (gs, l1_err,  l2_err, li_err,\n",
        "                                     rel_l1_err, rel_l2_err, rel_li_err, lr,\n",
        "                                     t1_train - t0_train, t_mc - t1_train))\n",
        "        file_out.flush()\n",
        "\n",
        "    t0_train = time.time()\n",
        "    is_training = tf.compat.v1.placeholder(tf.bool, [])\n",
        "    u_approx = neural_net(xi, neurons, is_training, 'u_approx', dtype=dtype)\n",
        "    loss = tf.reduce_mean(input_tensor=tf.math.squared_difference(u_approx, phi(x_sde)))\n",
        "\n",
        "    err = tf.abs(u_approx - u_reference)\n",
        "    err_l_1 = tf.reduce_mean(input_tensor=err)\n",
        "    err_l_2 = tf.reduce_mean(input_tensor=err ** 2)\n",
        "    err_l_inf = tf.reduce_max(input_tensor=err)\n",
        "    rel_err = err / tf.maximum(u_reference, 1e-8)\n",
        "    rel_err_l_1 = tf.reduce_mean(input_tensor=rel_err)\n",
        "    rel_err_l_2 = tf.reduce_mean(input_tensor=rel_err ** 2)\n",
        "    rel_err_l_inf = tf.reduce_max(input_tensor=rel_err)\n",
        "\n",
        "    global_step = tf.compat.v1.get_variable('global_step', [], tf.int32,\n",
        "                                  tf.compat.v1.constant_initializer(0),\n",
        "                                  trainable=False)\n",
        "    learning_rate = tf.compat.v1.train.piecewise_constant(global_step,\n",
        "                                                lr_boundaries,\n",
        "                                                lr_values)\n",
        "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate)\n",
        "    update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS, 'u_approx')\n",
        "    with tf.control_dependencies(update_ops):\n",
        "        train_op = optimizer.minimize(loss, global_step)\n",
        "\n",
        "    file_out = open(file_name, 'w')\n",
        "    file_out.write('step, l1_err, l2_err, li_err, l1_rel, '\n",
        "                   'l2_rel, li_rel, learning_rate, time_train, time_mc\\n')\n",
        "\n",
        "    with tf.compat.v1.Session() as sess:\n",
        "\n",
        "        sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "        for step in tqdm(range(train_steps)):\n",
        "            if step % mc_freq == 0:\n",
        "                t1_train = time.time()\n",
        "                _approximate_errors()\n",
        "                t0_train = time.time()\n",
        "            sess.run(train_op, feed_dict={is_training: True})\n",
        "        t1_train = time.time()\n",
        "        _approximate_errors()\n",
        "\n",
        "    file_out.close()"
      ],
      "metadata": {
        "id": "QYhRLQ4SHdwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example\n",
        "\n",
        "## Heat Equation"
      ],
      "metadata": {
        "id": "TjH5g03QsznE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.reset_default_graph()\n",
        "dtype = tf.float32\n",
        "T, N, d = 1., 1, 100\n",
        "batch_size = 8192\n",
        "neurons = [20, 1]\n",
        "train_steps = 300000\n",
        "mc_rounds, mc_freq = 1250, 100\n",
        "lr_boundaries = [250001, 500001]\n",
        "lr_values = [0.001, 0.0001, 0.00001]\n",
        "xi = tf.random.uniform(shape=(batch_size, d), minval=0.,\n",
        "                       maxval=1., dtype=dtype)\n",
        "x_sde = xi + tf.random.normal(shape=(batch_size, d),\n",
        "                              stddev=np.sqrt(2. * T / N), dtype=dtype)\n",
        "\n",
        "def phi(x):\n",
        "    return tf.reduce_sum(input_tensor=x ** 2, axis=1, keepdims=True)\n",
        "\n",
        "u_reference = phi(xi) + 2. * T * d\n",
        "\n",
        "kolmogorov_train_and_test(xi, x_sde, phi, u_reference, neurons,\n",
        "                          lr_boundaries, lr_values, train_steps,\n",
        "                          mc_rounds, mc_freq, 'example_heat_equation_single_20.csv', dtype)"
      ],
      "metadata": {
        "id": "H1zqqxaeDZqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f8b6b9-e6d0-4dfb-a536-9647484c726b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300000/300000 [1:57:14<00:00, 42.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geometric Brownian Motion"
      ],
      "metadata": {
        "id": "JUY_jLets5Sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.reset_default_graph()\n",
        "dtype = tf.float32\n",
        "T, N, d = 1., 1, 100\n",
        "r, c, K = 0.05, 0.1, 100.\n",
        "sigma = tf.constant(0.1 + 0.5 * np.linspace(start=1. / d, stop=1., num=d, endpoint=True), dtype=dtype)\n",
        "batch_size = 8192\n",
        "neurons = [d + 100, d + 100, 1]\n",
        "train_steps = 300000\n",
        "# mc_rounds, mc_freq = 1250, 100\n",
        "mc_rounds, mc_freq = 10, 25000\n",
        "mc_samples_ref, mc_rounds_ref = 1024, 1024\n",
        "lr_boundaries = [250001, 500001]\n",
        "lr_values = [0.001, 0.0001, 0.00001]\n",
        "xi = tf.random.uniform((batch_size, d), minval=90., maxval=110., dtype=dtype)\n",
        "\n",
        "\n",
        "def phi(x, axis=1):\n",
        "    return tf.exp(-r * T) \\\n",
        "           * tf.maximum(tf.reduce_max(input_tensor=x, axis=axis, keepdims=True) - K, 0.)\n",
        "\n",
        "\n",
        "def mc_body(idx, p):\n",
        "    _x = xi * tf.exp((r - c - 0.5 * sigma ** 2) * T + sigma\n",
        "                     * tf.random.normal((mc_samples_ref, batch_size, d),\n",
        "                                        stddev=tf.sqrt(T / N), dtype=dtype))\n",
        "    return idx + 1, p + tf.reduce_mean(input_tensor=phi(_x, 2), axis=0)\n",
        "\n",
        "\n",
        "x_sde = xi * tf.exp((r - c - 0.5 * sigma ** 2) * T\n",
        "                    + sigma * tf.random.normal((batch_size, d),\n",
        "                                               stddev=tf.sqrt(T / N),\n",
        "                                               dtype=dtype))\n",
        "_, u = tf.while_loop(cond=lambda idx, p: idx < mc_rounds_ref, body=mc_body,\n",
        "                     loop_vars=(tf.constant(0), tf.zeros((batch_size, 1), dtype)))\n",
        "u_reference = u / tf.cast(mc_rounds_ref, tf.float32)\n",
        "\n",
        "kolmogorov_train_and_test(xi, x_sde, phi, u_reference, neurons,\n",
        "                          lr_boundaries, lr_values, train_steps,\n",
        "                          mc_rounds, mc_freq, 'example_geometric_brownian_motions.csv', dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "tkYM1FkRi9s-",
        "outputId": "802fbfe0-6d73-4fb4-b87d-70abd62ec59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/300000 [00:00<?, ?it/s]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [02:53<26:02, 173.66s/it]\u001b[A\n",
            " 20%|██        | 2/10 [05:47<23:08, 173.55s/it]\u001b[A\n",
            " 30%|███       | 3/10 [08:40<20:14, 173.52s/it]\u001b[A\n",
            " 40%|████      | 4/10 [11:34<17:21, 173.50s/it]\u001b[A\n",
            " 50%|█████     | 5/10 [14:27<14:27, 173.47s/it]\u001b[A\n",
            " 60%|██████    | 6/10 [17:20<11:33, 173.46s/it]\u001b[A\n",
            " 70%|███████   | 7/10 [20:14<08:40, 173.51s/it]\u001b[A\n",
            " 80%|████████  | 8/10 [23:08<05:47, 173.51s/it]\u001b[A\n",
            " 90%|█████████ | 9/10 [26:01<02:53, 173.49s/it]\u001b[A\n",
            "100%|██████████| 10/10 [28:54<00:00, 173.50s/it]\n",
            "  8%|▊         | 24997/300000 [31:02<23:01, 199.00it/s]\n",
            "  8%|▊         | 24997/300000 [31:21<23:01, 199.00it/s]\n",
            " 10%|█         | 1/10 [05:46<52:02, 346.96s/it]\n",
            "  8%|▊         | 25000/300000 [36:49<6:45:08, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-bf62606e3a1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mu_reference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmc_rounds_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m kolmogorov_train_and_test(xi, x_sde, phi, u_reference, neurons,\n\u001b[0m\u001b[1;32m     38\u001b[0m                           \u001b[0mlr_boundaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                           mc_rounds, mc_freq, 'example_geometric_brownian_motions.csv', dtype)\n",
            "\u001b[0;32m<ipython-input-14-5cbed0913903>\u001b[0m in \u001b[0;36mkolmogorov_train_and_test\u001b[0;34m(xi, x_sde, phi, u_reference, neurons, lr_boundaries, lr_values, train_steps, mc_rounds, mc_freq, file_name, dtype)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmc_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mt1_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0m_approximate_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mt0_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-5cbed0913903>\u001b[0m in \u001b[0;36m_approximate_errors\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmc_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrli\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 = sess.run([err_l_1, err_l_2, err_l_inf,\n\u001b[0m\u001b[1;32m     13\u001b[0m                             rel_err_l_1, rel_err_l_2, rel_err_l_inf],\n\u001b[1;32m     14\u001b[0m                            feed_dict={is_training: False})\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1371\u001b[0m                            run_metadata)\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1375\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1361\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1451\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1452\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1453\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1454\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m                                             run_metadata)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mUDoFEiitbkq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}